{% load static %}

<!DOCTYPE html>
<html>
<title>DAIR Perception</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
body, h1,h2,h3,h4,h5,h6 {font-family: "Montserrat", sans-serif}
.w3-row-padding img {margin-bottom: 12px}
/* Set the width of the sidebar to 120px */
.w3-sidebar {width: 120px;background: #222;}
/* Add a left margin to the "page content" that matches the width of the sidebar (120px) */
#main {margin-left: 120px}
/* Remove margins from "page content" on small screens */
@media only screen and (max-width: 600px) {#main {margin-left: 0}}
</style>
<body class="w3-black">

<!-- Icon Bar (Sidebar - hidden on small screens) -->
<nav class="w3-sidebar w3-bar-block w3-small w3-hide-small w3-center">
  <!-- Avatar image in top left corner -->
  <a href="https://qmind.ca/">
  <img src="{% static 'main/images/qmindlogo.png' %}" alt='QMIND' style="width:50%">
  </a>
  <a href="/main/" class="w3-bar-item w3-button w3-padding-large w3-hover-black">
    <i class="fa fa-search w3-xxlarge"></i>
    <p>ROBOT LAUNCH</p>
  </a>
  <a href="/main/about/" class="w3-bar-item w3-button w3-padding-large w3-hover-black">
    <i class="fa fa-user w3-xxlarge"></i>
    <p>ABOUT US</p>
  </a>
  <a href="/main/images/" class="w3-bar-item w3-button w3-padding-large w3-black">
    <i class="fa fa-eye w3-xxlarge"></i>
    <p>PHOTOS</p>
  </a>
  <a href="http://cucai.ca/">
    <img src="{% static 'main/images/cucailogo.jpg' %}" alt='CUCAI' style="width:75%">
  </a>
</nav>

<!-- Navbar on small screens (Hidden on medium and large screens) -->
<div class="w3-top w3-hide-large w3-hide-medium" id="myNavbar">
  <div class="w3-bar w3-black w3-opacity w3-hover-opacity-off w3-center w3-small">
    <a href="#" class="w3-bar-item w3-button" style="width:25% !important">HOME</a>
    <a href="#about" class="w3-bar-item w3-button" style="width:25% !important">ABOUT</a>
    <a href="#photos" class="w3-bar-item w3-button" style="width:25% !important">PHOTOS</a>
    <a href="#contact" class="w3-bar-item w3-button" style="width:25% !important">CONTACT</a>
  </div>
</div>

<!-- Page Content -->
<div class="w3-padding-large" id="main">
    <!-- Header/Home -->
    <header class="w3-container w3-padding-32 w3-center w3-black" id="home">
      <h1 class="w3-jumbo"><span class="w3-hide-small">DAIR Perception</span></h1>
      <h2>Media</h2>
    </header>


<!-- Grid for photos -->
<div class="w3-row-padding w3-center" style="margin:0 -16px">
    <div class="w3-center">
      <img src="{% static 'main/images/yolo-visual.PNG' %}" style="width:75%"> 
      <p> <b>The YOLO Detection System:</b> The YOLO model is an approach to object detection where the image is passed through
             a single neural network. Using this unified implementation for object detection, the system only has to look once (YOLO)
             to make accurate predictions.  </p>
      <img src="{% static 'main/images/yolov3-accuracy-vs-time.PNG' %}" style="width:75%">
      <p> YOLO's single pass regression system that doesn't require complex pipelines enables it to perform at unparalleled
          speeds. In addition, the approach of passing the entire image through the model (as opposed to sliding window and regional-based
          solutions) decreases the amount of background errors. The speed and accuracy in high-context environments makes it an ideal model
          for real-time object detection on our robot.
      </p>
      <img src="{% static 'main/images/ros-visual.png' %}" style="width:75%">
      <p> In order to develop an effective real-time solution on the robot, we designed nodes in ROS (Robot Operating System) for the computer, 
          robot and sensors to exchange data. Data from the camera and LiDAR sensor are published to nodes through ROS, and the python scripts
          subscribe to this information. The scripts make decisions on the newest data based off the neural network and movement algorithms, addition
          decide how they want to control the robot. Desicions are published to new nodes, where the robot motors can read and execute the data.
      </p>
      <img src="{% static 'main/images/coco.png' %}" style="width:75%"> 
      <p> We wanted to train our object detection model on a labelled dataset that showcased objects in dynamic and context-rich environments. COCO 
          consists of exactly that, a collection of common objects in real environments. By selecting the classes we wanted to train our model on, we
          were able to fine tune the object detection to perform for our given use cases.
      </p>
    </div>

    </html>