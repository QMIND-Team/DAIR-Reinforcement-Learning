{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Object Detection with YOLOv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! Thanks for checking out this Jupyter Notebook. The goal of this notebook is to showcase how to train your own YOLOv3 model to perform real-time object detection. This trained model will later be exported to a Turtlebot3 to enhance the robot perception system. But for now, we will focus on the best methods to approach preparing our data and training the model, and test our findings on still images. Hope you enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook was created by **Sam Cantor** for use in *QMIND* and the *DAIR-Perception* team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the pre-trained YOLOv3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to give a huge thanks to Sergio Canu's tutorial on how to get started with YOLO using python and openCV. You can check it out [here](https://pysource.com/2019/06/27/yolo-object-detection-using-opencv-with-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries and relevant files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using *openCV* to interact with the YOLO algorithm. This framework is best for beginners to start with, but has a slower performance than other methods as it only work with CPU. *Darknet* and *Darkflow* can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load in the pre-trained YOLO model and the COCO dataset that it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = net.getLayerNames()\n",
    "outputlayers = [layer_names[i[0]-1]for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.uniform(0,255,size=(len(classes),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load an image\n",
    "img = cv2.imread(\"dogandhorsepic.jpg\")\n",
    "img = cv2.resize(img,None,fx=1.5,fy=1.3)\n",
    "height,width,channels = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"Image\",img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting objects\n",
    "blob = cv2.dnn.blobFromImage(img, 0.00392, (416,316), (0,0,0), True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b in blob:\n",
    "#     for n,img_blob in enumerate(b):\n",
    "#         cv2.imshow(str(n),img_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02599529 0.0297504  0.05962627 ... 0.         0.         0.        ]\n",
      " [0.01683626 0.02414035 0.3507023  ... 0.         0.         0.        ]\n",
      " [0.02303046 0.02407526 0.08258578 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.9782416  0.97337496 0.03609551 ... 0.         0.         0.        ]\n",
      " [0.9832626  0.9758237  0.34377223 ... 0.         0.         0.        ]\n",
      " [0.9822391  0.9763198  0.06413222 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "net.setInput(blob)\n",
    "outs = net.forward(outputlayers)\n",
    "print(outs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids=[]\n",
    "confidences=[]\n",
    "boxes=[]\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0]*width)\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            #circle in center of object\n",
    "            cv2.circle(img,(center_x,center_y),5,(0,255,0),2)\n",
    "            #rectangle around object\n",
    "            x=int(center_x - w/2)\n",
    "            y=int(center_y - h/2)\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            #put text\n",
    "            cv2.putText(img,str(classes[class_id])+'->'+str(confidence),(x,y+30),font,1,(0,0,255),2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to see the result of above code\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
